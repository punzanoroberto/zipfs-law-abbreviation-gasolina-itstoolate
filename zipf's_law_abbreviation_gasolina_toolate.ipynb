{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "GenAI (GPT-5 and GEMINI) has been used to do this project as a helping tool. This project has been created only by Roberto Punzano, without the help of any other human."
      ],
      "metadata": {
        "id": "1_xuEHALdnC5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Importing Libraries"
      ],
      "metadata": {
        "id": "9O7aXkho3H4E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zl00xJ5E29o_",
        "outputId": "0e22be32-1fe1-4b95-a5f8-b1df83207591"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting es-core-news-sm==3.8.0\n",
            "  Using cached https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.8.0/es_core_news_sm-3.8.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download es_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy #for tokenization and POS Tagging\n",
        "from scipy.stats import spearmanr #scipy used to compute Spearman Correlation"
      ],
      "metadata": {
        "id": "QpV7Y_Rc3MgM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Preparing the Data and Tokenizing"
      ],
      "metadata": {
        "id": "Jdt-dDiO3OcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Opening the .txt for the Spanish Song\n",
        "with open(\"/content/gasolina.txt\", encoding=\"utf-8\") as f:\n",
        "    spanish_text = f.read()"
      ],
      "metadata": {
        "id": "SKPCRI5g4QB9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Opening the .txt for the English Song\n",
        "with open(\"/content/its_too_late.txt\", encoding=\"utf-8\") as f:\n",
        "    english_text = f.read()"
      ],
      "metadata": {
        "id": "3JtYfi2sKS09"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing the Text by Words with SpaCy\n",
        "def tokenize_text(text, language=\"en\"):\n",
        "    if language == \"es\":\n",
        "        nlp = spacy.load(\"es_core_news_sm\")\n",
        "    elif language == \"en\":\n",
        "        nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "    doc = nlp(text)   #tokenizing the text\n",
        "    words = [token.text.lower() for token in doc if token.is_alpha]   #converting all tokens into lower case if they are letters\n",
        "    return words      #list of words"
      ],
      "metadata": {
        "id": "974Rfw1dVVKb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying SpaCy Tokenization Function\n",
        "english_tokenized = tokenize_text(english_text, language=\"en\")\n",
        "spanish_tokenized = tokenize_text(spanish_text, language=\"es\")"
      ],
      "metadata": {
        "id": "DUiJvVxSXNDa"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Creating a Dictionary with Words and their Frequency"
      ],
      "metadata": {
        "id": "EUO4dKtZ8m5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapping the Words with their Frequencies\n",
        "\n",
        "def getting_frequencies(tokenized_text):\n",
        "  word_frequency = {}      #creating a dictionary\n",
        "\n",
        "  for word in tokenized_text:\n",
        "    if word in word_frequency:    #if the word is in the dictionary\n",
        "      word_frequency[word] += 1   #we add 1 to the value store frequency\n",
        "    else:\n",
        "      word_frequency[word] = 1    #if it has not been seen yet, we set its value to 1\n",
        "  return word_frequency"
      ],
      "metadata": {
        "id": "4txWXcEM32jM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying Frequencies Function\n",
        "english_frequencies = getting_frequencies(english_tokenized)\n",
        "spanish_frequencies = getting_frequencies(spanish_tokenized)"
      ],
      "metadata": {
        "id": "HAPqGgnFYMUW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Adding Length"
      ],
      "metadata": {
        "id": "5K5z26XS8vcv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We add Length with another dictionary\n",
        "\n",
        "def freq_and_length_dict(frequencies):\n",
        "  word_freq_length = {}\n",
        "\n",
        "  for word, freq in frequencies.items():   #here we take the previous dictionary\n",
        "    length = len(word)                        #we create a new variable storing length\n",
        "    word_freq_length[word] = (freq, length)   #and we map it into a tupple as a value\n",
        "  return word_freq_length"
      ],
      "metadata": {
        "id": "iDklaJK_8xod"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying Length Function\n",
        "english_data = freq_and_length_dict(english_frequencies)\n",
        "spanish_data = freq_and_length_dict(spanish_frequencies)"
      ],
      "metadata": {
        "id": "HL5kdVrxZl5p"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Computing Spearman Correlation to Test Zipf's Law of Abbreviaton"
      ],
      "metadata": {
        "id": "7k01D-FPIGMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the Tuple into 2 Lists (needed for SciPy)\n",
        "\n",
        "def tuple_into_lists(data_dict):\n",
        "  frequencies = []\n",
        "  lengths = []\n",
        "\n",
        "  for freq, length in data_dict.values():    #for all the values\n",
        "      frequencies.append(freq)    #append frequencies into the new frequencies list\n",
        "      lengths.append(length)      #append length into the new length list\n",
        "  return frequencies, lengths"
      ],
      "metadata": {
        "id": "6RLQ2gZHIMue"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying Tupple to List Function\n",
        "english_lists = tuple_into_lists(english_data)\n",
        "spanish_lists = tuple_into_lists(spanish_data)"
      ],
      "metadata": {
        "id": "NbLy7ouHaVhC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We compute Spearman Correlation with SciPy\n",
        "def spearman_correlation(frequencies, lengths):\n",
        "  rho, p_value = spearmanr(frequencies, lengths)   #computing rho and p-value by taking freqs and lengths\n",
        "  return rho, p_value"
      ],
      "metadata": {
        "id": "kXC07U2_I7M8"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing Rho and P-value\n",
        "\"\"\"\n",
        "These lines take the Spearman Correlation function and applies it to the Spanish and\n",
        "English data. The * operator unpacks the two elements in the list and\n",
        "\"\"\"\n",
        "english_rho, english_p_value = spearman_correlation(*english_lists)\n",
        "spanish_rho, spanish_p_value = spearman_correlation(*spanish_lists)"
      ],
      "metadata": {
        "id": "zMsqFW5UbEEw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ENGLISH RESULTS\n",
        "print(\"ENGLISH RESULTS:\")\n",
        "print(\"Spearman rho:\", english_rho)\n",
        "print(\"p-value:\", english_p_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDK_H7viJH3H",
        "outputId": "aafbdaed-8e1b-4e37-d543-5bc34a909637"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENGLISH RESULTS:\n",
            "Spearman rho: -0.35618333962927606\n",
            "p-value: 0.0011839854793753543\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SPANISH RESULTS\n",
        "print(\"SPANISH RESULTS:\")\n",
        "print(\"Spearman rho:\", spanish_rho)\n",
        "print(\"p-value:\", spanish_p_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPnPTxoPeAkw",
        "outputId": "f2cfa6a6-d74e-462b-bb50-89ba55770f07"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SPANISH RESULTS:\n",
            "Spearman rho: -0.506177254088844\n",
            "p-value: 6.7678569425985604e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Qualitative Analysis"
      ],
      "metadata": {
        "id": "xqADCtkqLaXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "english_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bY9w8i7nLdSU",
        "outputId": "1509971a-c2e9-4f54-e67c-75fdc4759c96"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'stayed': (1, 6),\n",
              " 'in': (1, 2),\n",
              " 'bed': (1, 3),\n",
              " 'all': (1, 3),\n",
              " 'morning': (1, 7),\n",
              " 'just': (5, 4),\n",
              " 'to': (4, 2),\n",
              " 'pass': (1, 4),\n",
              " 'the': (1, 3),\n",
              " 'time': (1, 4),\n",
              " 'there': (3, 5),\n",
              " 'something': (2, 9),\n",
              " 'wrong': (1, 5),\n",
              " 'here': (2, 4),\n",
              " 'can': (1, 3),\n",
              " 'be': (3, 2),\n",
              " 'no': (4, 2),\n",
              " 'denying': (1, 7),\n",
              " 'one': (1, 3),\n",
              " 'of': (1, 2),\n",
              " 'us': (1, 2),\n",
              " 'is': (1, 2),\n",
              " 'changing': (1, 8),\n",
              " 'or': (1, 2),\n",
              " 'maybe': (1, 5),\n",
              " 'we': (4, 2),\n",
              " 'stopped': (1, 7),\n",
              " 'trying': (1, 6),\n",
              " 'and': (8, 3),\n",
              " 'it': (8, 2),\n",
              " 'too': (6, 3),\n",
              " 'late': (5, 4),\n",
              " 'baby': (2, 4),\n",
              " 'now': (3, 3),\n",
              " 'though': (1, 6),\n",
              " 'really': (1, 6),\n",
              " 'did': (1, 3),\n",
              " 'try': (1, 3),\n",
              " 'make': (1, 4),\n",
              " 'inside': (1, 6),\n",
              " 'has': (1, 3),\n",
              " 'died': (1, 4),\n",
              " 'i': (6, 1),\n",
              " 'ca': (3, 2),\n",
              " 'hide': (1, 4),\n",
              " 'fake': (1, 4),\n",
              " 'oh': (1, 2),\n",
              " 'used': (1, 4),\n",
              " 'so': (2, 2),\n",
              " 'easy': (1, 4),\n",
              " 'living': (1, 6),\n",
              " 'with': (1, 4),\n",
              " 'you': (6, 3),\n",
              " 'were': (1, 4),\n",
              " 'light': (1, 5),\n",
              " 'breezy': (1, 6),\n",
              " 'knew': (1, 4),\n",
              " 'what': (2, 4),\n",
              " 'do': (2, 2),\n",
              " 'look': (1, 4),\n",
              " 'unhappy': (1, 7),\n",
              " 'feel': (2, 4),\n",
              " 'like': (1, 4),\n",
              " 'a': (1, 1),\n",
              " 'fool': (1, 4),\n",
              " 'good': (1, 4),\n",
              " 'times': (1, 5),\n",
              " 'again': (1, 5),\n",
              " 'for': (2, 3),\n",
              " 'me': (1, 2),\n",
              " 'but': (1, 3),\n",
              " 'stay': (1, 4),\n",
              " 'together': (1, 8),\n",
              " 'still': (1, 5),\n",
              " 'glad': (1, 4),\n",
              " 'had': (1, 3),\n",
              " 'how': (1, 3),\n",
              " 'once': (1, 4),\n",
              " 'loved': (1, 5),\n",
              " 'darling': (1, 7)}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spanish_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xd_m5LMnLhLM",
        "outputId": "ef3bccf9-bec5-4fe2-cbdb-7aca644ab72d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'zúmbale': (1, 7),\n",
              " 'mambo': (1, 5),\n",
              " 'para': (9, 4),\n",
              " 'que': (13, 3),\n",
              " 'mis': (1, 3),\n",
              " 'gatas': (2, 5),\n",
              " 'prendan': (1, 7),\n",
              " 'los': (6, 3),\n",
              " 'motores': (2, 7),\n",
              " 'se': (5, 2),\n",
              " 'preparen': (1, 8),\n",
              " 'lo': (3, 2),\n",
              " 'viene': (1, 5),\n",
              " 'es': (2, 2),\n",
              " 'le': (5, 2),\n",
              " 'den': (1, 3),\n",
              " 'duro': (4, 4),\n",
              " 'mamita': (1, 6),\n",
              " 'yo': (2, 2),\n",
              " 'sé': (1, 2),\n",
              " 'tú': (5, 2),\n",
              " 'no': (7, 2),\n",
              " 'te': (3, 2),\n",
              " 'me': (5, 2),\n",
              " 'vas': (1, 3),\n",
              " 'a': (4, 1),\n",
              " 'quitar': (1, 6),\n",
              " 'gusta': (2, 5),\n",
              " 'dejas': (1, 5),\n",
              " 'llevar': (1, 6),\n",
              " 'todos': (2, 5),\n",
              " 'fines': (1, 5),\n",
              " 'de': (6, 2),\n",
              " 'semana': (1, 6),\n",
              " 'ella': (4, 4),\n",
              " 'sale': (1, 4),\n",
              " 'vacilar': (1, 7),\n",
              " 'mi': (1, 2),\n",
              " 'gata': (1, 4),\n",
              " 'janguear': (1, 8),\n",
              " 'porque': (1, 6),\n",
              " 'la': (6, 2),\n",
              " 'gasolina': (4, 8),\n",
              " 'dame': (2, 4),\n",
              " 'más': (3, 3),\n",
              " 'cómo': (1, 4),\n",
              " 'encanta': (1, 7),\n",
              " 'prende': (1, 6),\n",
              " 'las': (6, 3),\n",
              " 'turbinas': (1, 8),\n",
              " 'discrimina': (1, 10),\n",
              " 'pierde': (2, 6),\n",
              " 'ni': (1, 2),\n",
              " 'una': (1, 3),\n",
              " 'fiesta': (1, 6),\n",
              " 'marquesina': (1, 10),\n",
              " 'acicala': (1, 7),\n",
              " 'hasta': (2, 5),\n",
              " 'esquina': (1, 7),\n",
              " 'luce': (1, 4),\n",
              " 'tan': (1, 3),\n",
              " 'bien': (1, 4),\n",
              " 'sombra': (1, 6),\n",
              " 'combina': (1, 7),\n",
              " 'asesina': (1, 7),\n",
              " 'domina': (1, 6),\n",
              " 'janguea': (1, 7),\n",
              " 'en': (3, 2),\n",
              " 'carros': (1, 6),\n",
              " 'motoras': (1, 7),\n",
              " 'y': (3, 1),\n",
              " 'limusinas': (1, 9),\n",
              " 'llena': (1, 5),\n",
              " 'su': (1, 2),\n",
              " 'tanque': (1, 6),\n",
              " 'adrenalina': (1, 10),\n",
              " 'cuando': (2, 6),\n",
              " 'escucha': (1, 7),\n",
              " 'reguetón': (1, 8),\n",
              " 'cocina': (1, 6),\n",
              " 'aquí': (1, 4),\n",
              " 'nosotros': (1, 8),\n",
              " 'somos': (1, 5),\n",
              " 'mejores': (1, 7),\n",
              " 'ajores': (1, 6),\n",
              " 'pista': (1, 5),\n",
              " 'nos': (1, 3),\n",
              " 'llaman': (1, 6),\n",
              " 'matadores': (1, 9),\n",
              " 'haces': (1, 5),\n",
              " 'cualquiera': (1, 10),\n",
              " 'enamore': (1, 7),\n",
              " 'bailas': (1, 6),\n",
              " 'al': (1, 2),\n",
              " 'ritmo': (1, 5),\n",
              " 'tambores': (1, 8),\n",
              " 'esto': (1, 4),\n",
              " 'va': (1, 2),\n",
              " 'colores': (1, 7),\n",
              " 'mayores': (1, 7),\n",
              " 'menores': (1, 7),\n",
              " 'son': (1, 3),\n",
              " 'zorras': (1, 6),\n",
              " 'cazadores': (1, 9),\n",
              " 'mujeres': (1, 7),\n",
              " 'apagan': (1, 6),\n",
              " 'sus': (1, 3),\n",
              " 'tenemos': (1, 7),\n",
              " 'algo': (2, 4),\n",
              " 'pendiente': (1, 9),\n",
              " 'debes': (1, 5),\n",
              " 'sabes': (1, 5),\n",
              " 'conmigo': (1, 7),\n",
              " 'rinde': (1, 5),\n",
              " 'cuentas': (1, 7),\n",
              " 'nadie': (1, 5)}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}